# Task Manager (DRF) — Alliance

Кратко: реализация REST API для управления задачами пользователей, развернута в Docker (docker-compose) с PostgreSQL.
<!-- TOC -->
* [Task Manager (DRF) — Alliance](#task-manager-drf--alliance)
  * [Инициализация проекта](#инициализация-проекта)
  * [Предварительные требования](#предварительные-требования)
  * [Запуск через Docker](#запуск-через-docker)
  * [Архитектура проекта](#архитектура-проекта)
  * [Ограничения и упрощения](#ограничения-и-упрощения)
    * [Локально в контейнере](#локально-в-контейнере)
    * [Или через tester сервис (запустит и завершится)](#или-через-tester-сервис-запустит-и-завершится)
  * [API Endpoints](#api-endpoints)
  * [Краткие примеры запросов (Postman Collection)](#краткие-примеры-запросов-postman-collection)
  * [Использование ИИ в проекте](#использование-ии-в-проекте)
<!-- TOC -->

## Инициализация проекта

1. Клонируйте репозиторий:

   ```bash
   git clone https://github.com/fletch4503/gksalliance.git
   cd gksalliance
   ```

2. Установите зависимости и настройте окружение:
   * Для запуска через Docker: Следуйте разделу ["Запуск через Docker"](#запуск-через-docker).

## Предварительные требования
[Home](#task-manager-drf--alliance)
* Python >= 3.13
* UV (для управления зависимостями)
* Docker и Docker Compose (для запуска в контейнерах)

## Запуск через Docker
[Home](#task-manager-drf--alliance)
1. Скопируйте `.env.example` в `.env` и при необходимости поправьте значения (например, пароли базы данных).

2. Поднимите контейнеры:

   ```bash
   docker-compose up --build -d
   ```

   Скрипт `prestart.sh` внутри контейнера автоматически выполнит миграции базы данных и создаст тестовых пользователей 
   (2 admin, 3 обычных пользователя).

3. API будет доступно на `http://localhost:8000`.

## Архитектура проекта
[Home](#task-manager-drf--alliance)

Проект построен на базе Django и Django REST Framework (DRF), что обеспечивает быструю разработку RESTful API. Основная структура разделена на несколько слоев для обеспечения модульности и поддерживаемости.

Корневой каталог `alliance_project/` содержит конфигурацию Django-проекта: настройки (`settings.py`), маршрутизацию URL (`urls.py`) и WSGI-конфигурацию для развертывания. Это стандартная структура Django, позволяющая централизованно управлять конфигурацией приложения.

Приложение `tasks/` реализует всю бизнес-логику управления задачами. Внутри него выделены следующие компоненты:

* `models.py`: Определяет модель `Task` с полями для заголовка, описания, статуса, срока выполнения, владельца и флага просроченности. Модель использует стандартные Django-модели с ForeignKey для связи с пользователем.
* `serializers.py`: Содержит `TaskSerializer` для валидации входных данных и сериализации объектов в JSON. Включает кастомную валидацию, например, обязательность `due_date` при статусе "done".
* `views.py`: Реализует `TaskViewSet` на базе DRF ViewSet для CRUD-операций над задачами. Включает фильтрацию, пагинацию и разрешения доступа.
* `services.py`: Выносит бизнес-логику в отдельный слой, например, функцию `recalc_overdue` для пересчета просроченных задач на основе текущего времени.
* Дополнительные модули: `authentication.py` для кастомной аутентификации, `permissions.py` для контроля доступа, `filters.py` для фильтрации запросов, `pagination.py` для пагинации результатов.

Управление зависимостями осуществляется через `pyproject.toml` и `uv.lock`, что обеспечивает воспроизводимую установку пакетов. Docker-конфигурация (`Dockerfile`, `docker-compose.yml`) позволяет развернуть приложение в контейнерах с PostgreSQL как базой данных, обеспечивая изоляцию и масштабируемость.

Такая архитектура следует принципам разделения ответственности: 
модели управляют данными, сериализаторы — валидацией и представлением, представления — логикой API, 
а сервисы — сложной бизнес-логикой. Это упрощает тестирование, поддержку и расширение проекта.

## Ограничения и упрощения
[Home](#task-manager-drf--alliance)

Проект использует упрощенную модель аутентификации через заголовок `X-User-Id`, что подходит для демонстрационных целей, 
но не рекомендуется для production из-за отсутствия токенов или сессий. 
Пользователи создаются автоматически скриптом `create_test_data`, без полноценной регистрации.

Владельца задачи (`owner`) нельзя изменить через API — поле помечено как `read_only`, что предотвращает передачу 
задач между пользователями, но ограничивает гибкость в многопользовательских сценариях.

Валидация требует `due_date` при установке статуса "done", что обеспечивает целостность данных, 
но добавляет жесткость в логике.

База данных — PostgreSQL, но миграции простые, без сложных индексов или оптимизаций производительности. 
Тесты покрывают основные сценарии.

Сервис `recalc_overdue` запускается вручную или периодически, без фоновых задач (например, Celery), 
что упрощает развертывание, но может не подойти для высоконагруженных систем.

Запуск тестов через Docker:

### Локально в контейнере

```bash
docker-compose exec web python manage.py test
```

### Или через tester сервис (запустит и завершится)

```bash
docker-compose run --rm tester
```

## API Endpoints
[Home](#task-manager-drf--alliance)
* `POST /api/tasks/` — создать задачу
* `GET /api/tasks/{id}/` — получить задачу
* `PUT/PATCH /api/tasks/{id}/` — обновить (PUT - все поля, PATCH - частично)
* `DELETE /api/tasks/{id}/` — удалить
* `GET /api/tasks/` — список (фильтрация: `status`, `due_date_from`, `due_date_to`; пагинация: `page`, `size`)
* `POST /api/tasks/recalculate_overdue/` — ручной пересчёт (только admin)

## Краткие примеры запросов (Postman Collection)
[Home](#task-manager-drf--alliance)

Для тестирования API можно использовать Postman Collection файл в основной директории - postmancoll.json

## Использование ИИ в проекте
[Home](#task-manager-drf--alliance)

Для генерации архитектуры Django-приложения использовал Copilot и Kilo Code агенты с дальнейшей "ручной доработкой" 
архитектуры. Изначально "скармливал" переработанный файл задачи - gksalliance.md, где довалял некоторые требования
по виртуальному окружению и объему начальных данных для тестирования.